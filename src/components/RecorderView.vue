<template>
  <div class="h-full flex flex-col bg-white">
    <!-- Header -->
    <div class="border-b border-gray-200 px-6 py-4">
      <div class="flex items-center justify-between">
        <div>
          <h2 class="text-xl font-semibold text-gray-900">Nova Reuni√£o</h2>
          <p class="text-sm text-gray-500 mt-1">
            {{
              isRecording ? "Grava√ß√£o em andamento..." : "Pronto para gravar"
            }}
          </p>
        </div>

        <div class="flex items-center space-x-3">
          <StatusIndicator
            :is-active="isRecording"
            :status-text="
              isRecording ? formatDuration(recordingDuration) : 'Parado'
            "
          />
          <AudioCaptureIndicator
            v-if="isRecording || audioCaptureType !== 'unknown'"
            :capture-type="audioCaptureType"
            :is-capturing-full-meeting="isCapturingFullMeeting"
            :source-count="audioSources.length"
            :is-capturing-input="isCapturingInput"
            :is-capturing-output="isCapturingOutput"
            :audio-quality="audioQuality"
          />
          <RecordingControls
            :is-recording="isRecording"
            :is-supported="isSupported"
            :is-processing="isProcessing"
            :transcript="transcript"
            @start-recording="startRecording"
            @stop-recording="stopRecording"
            @clear-transcript="clearTranscript"
          />
        </div>
      </div>
    </div>

    <!-- Conte√∫do principal -->
    <div class="flex-1 overflow-y-auto p-6">
      <!-- Setup do BlackHole para captura completa -->
      <BlackHoleSetup v-if="!isRecording" @blackhole-configured="onBlackHoleConfigured" />

      <!-- Bot√£o de teste de captura de √°udio -->
      <AudioTestButton v-if="!isRecording" />


      <!-- Alerts -->
      <AlertBox
        v-if="error"
        type="error"
        title="Erro na grava√ß√£o"
        :message="error"
      />

      <AlertBox
        v-if="!isSupported"
        type="warning"
        title="Captura n√£o suportada"
        message="Nenhuma API de √°udio est√° dispon√≠vel. Verifique permiss√µes do sistema e reinicie o aplicativo."
      />

      <!-- Alerta espec√≠fico para Teams -->
      <AlertBox
        v-if="isRecording && !isCapturingOutput && audioCaptureType === 'microphone' && detectedMeetingApp.includes('Teams')"
        type="warning"
        title="üè¢ Microsoft Teams - Instru√ß√µes Especiais"
        message="O Teams detectado est√° bloqueando captura de √°udio. SOLU√á√ÉO: 1) Pare a grava√ß√£o 2) Inicie novamente 3) Quando aparecer o popup, escolha 'Compartilhar Tela' 4) MARQUE 'Compartilhar √°udio do sistema' 5) Selecione a tela/janela do Teams."
      />

      <!-- Alerta gen√©rico para outros casos -->
      <AlertBox
        v-if="isRecording && !isCapturingOutput && audioCaptureType === 'microphone' && !detectedMeetingApp.includes('Teams')"
        type="warning"
        title="‚ö†Ô∏è Capturando apenas sua voz"
        message="O √°udio dos outros participantes n√£o est√° sendo capturado. Para gravar reuni√µes completas, use compartilhamento de tela com √°udio ou configure um dispositivo de √°udio virtual."
      />

      <!-- Alerta quando captura h√≠brida pode n√£o estar funcionando -->
      <AlertBox
        v-if="isRecording && audioCaptureType === 'hybrid' && !isCapturingOutput && audioQuality.input === 0"
        type="warning"
        title="üîÑ Verificando captura h√≠brida"
        message="Tentando capturar √°udio do sistema. Se n√£o funcionar, ser√° usado apenas o microfone."
      />

      <!-- Alerta positivo quando est√° capturando entrada + sa√≠da -->
      <AlertBox
        v-if="isRecording && isCapturingInput && isCapturingOutput"
        type="success"
        title="‚úÖ Captura completa ativa"
        message="Gravando tanto sua voz quanto o √°udio dos outros participantes."
      />

      <!-- Status da API - Simplificado -->
      <AlertBox
        v-if="apiStatus && apiStatus.status === 'error'"
        type="error"
        title="API indispon√≠vel"
        :message="apiStatus.message"
      />

      <AlertBox
        v-if="isProcessing"
        type="info"
        title="Processando..."
        :message="!transcript ? 'Transcrevendo √°udio' : 'Gerando resumo'"
      />

      <!-- √Årea de transcri√ß√£o -->
      <div class="space-y-6">
        <TranscriptDisplay
          :transcript="transcript"
          :is-recording="isRecording"
        />

        <PostRecordingActions
          v-if="transcript && !isRecording && !isProcessing"
          @generate-summary="generateSummary"
          @download-transcript="downloadTranscript"
          @save-transcript="saveWithoutSummary"
        />

      </div>
    </div>
  </div>
</template>

<script setup>
import { onMounted, onUnmounted, ref, watch } from "vue";
import { useConfig } from "../composables/useConfig.js";
import { useHistory } from "../composables/useHistory.js";
import { useRecorder } from "../composables/useRecorder.js";
import {
  downloadFile,
  formatDuration,
  formatTimestamp,
} from "../utils/formatters.js";

// UI Components
import PostRecordingActions from "./recorder/PostRecordingActions.vue";
import RecordingControls from "./recorder/RecordingControls.vue";
import TranscriptDisplay from "./recorder/TranscriptDisplay.vue";
import AlertBox from "./ui/AlertBox.vue";
import AudioCaptureIndicator from "./ui/AudioCaptureIndicator.vue";
import AudioTestButton from "./ui/AudioTestButton.vue";
import BlackHoleSetup from "./ui/BlackHoleSetup.vue";
import StatusIndicator from "./ui/StatusIndicator.vue";

// Emits
const emit = defineEmits(["summary-generated"]);

// Composables
const {
  isRecording,
  isProcessing,
  isSupported,
  transcript,
  error,
  startRecording: startRec,
  stopRecording: stopRec,
  clearTranscript,
  transcribeAudio,
  generateSummaryFromTranscript,
  hasAudio,
  audioBlob,
  setOpenAIApiKey,
  testOpenAIConnection,
  estimateTranscriptionCost,
  hasOpenAIConfigured,
  // Novos: estado da captura de √°udio
  audioCaptureType,
  isCapturingFullMeeting,
  audioSources,
  isCapturingInput,
  isCapturingOutput,
  audioQuality,
  detectedMeetingApp,
} = useRecorder();

const { saveMeeting } = useHistory();
const { apiStatus } = useConfig();

// Estado local
const recordingDuration = ref(0);
let durationInterval = null;

// Listener para iniciar grava√ß√£o automaticamente (nova implementa√ß√£o)
let removeStartRecordingListener = null;

onMounted(() => {
  // Registra listener para detec√ß√£o autom√°tica de reuni√£o
  if (window.electronAPI?.onStartRecording) {
    removeStartRecordingListener = window.electronAPI.onStartRecording(
      (meetingData) => {
        console.log("üé¨ Reuni√£o detectada automaticamente:", meetingData);

        // Inicia grava√ß√£o automaticamente se n√£o estiver gravando
        if (!isRecording.value && !isProcessing.value) {
          console.log("üöÄ Iniciando grava√ß√£o autom√°tica...");
          startRecording();

          // Mostra notifica√ß√£o de feedback
          if (window.electronAPI?.showNotification) {
            window.electronAPI.showNotification(
              "Grava√ß√£o Iniciada",
              `Grava√ß√£o autom√°tica iniciada para ${meetingData.app}`
            );
          }
        } else {
          console.log("‚ö†Ô∏è Grava√ß√£o j√° em andamento, ignorando...");
        }
      }
    );
  }
});

// Limpa listener quando o componente √© desmontado
onUnmounted(() => {
  if (removeStartRecordingListener) {
    removeStartRecordingListener();
  }
  if (durationInterval) {
    clearInterval(durationInterval);
  }
});

// Usando fun√ß√£o utilitaria importada

// M√©todos
const startRecording = async () => {
  await startRec();
  if (isRecording.value) {
    recordingDuration.value = 0;
    durationInterval = setInterval(() => {
      recordingDuration.value++;
    }, 1000);
  }
};

const stopRecording = () => {
  stopRec();
  if (durationInterval) {
    clearInterval(durationInterval);
    durationInterval = null;
  }
};

const processAudio = async () => {
  if (!audioBlob.value) {
    alert("Nenhum √°udio capturado.");
    return;
  }
  try {
    const fileSizeMB = audioBlob.value.size / (1024 * 1024);
    const durationMinutes = (recordingDuration.value || 0) / 60;

    // Mostrar info do arquivo para o usu√°rio
    console.log(
      `üéµ Processando √°udio: ${fileSizeMB.toFixed(
        1
      )}MB, ${durationMinutes.toFixed(1)} minutos`
    );

    await transcribeAudio();

    if (window.electronAPI?.showNotification) {
      window.electronAPI.showNotification(
        "Transcri√ß√£o Conclu√≠da",
        `√Åudio de ${durationMinutes.toFixed(1)} min processado com sucesso!`
      );
    }
  } catch (err) {
    console.error("Erro ao transcrever √°udio:", err);

    // Mensagens de erro mais espec√≠ficas
    let errorMessage = "Erro ao transcrever √°udio. ";

    if (err.message.includes("limit") || err.message.includes("grande")) {
      errorMessage += "Processando reuni√£o longa em partes menores. Aguarde...";
    } else if (
      err.message.includes("timeout") ||
      err.message.includes("Timeout")
    ) {
      errorMessage += "A API demorou muito para processar. Tente novamente.";
    } else if (err.message.includes("API ausente")) {
      errorMessage += "Chave da API n√£o configurada. Verifique o arquivo .env";
    } else if (err.message.includes("upload")) {
      errorMessage += "Falha no upload do arquivo. Verifique sua conex√£o.";
    } else {
      errorMessage += err.message;
    }

    alert(errorMessage);
  }
};

const generateSummary = async () => {
  if (!transcript.value) {
    alert("Nenhuma transcri√ß√£o dispon√≠vel.");
    return;
  }
  try {
    const summary = await generateSummaryFromTranscript();
    const meeting = saveMeeting(transcript.value, summary);
    emit("summary-generated", meeting);
    if (window.electronAPI?.showNotification) {
      window.electronAPI.showNotification(
        "Resumo Gerado",
        "Resumo criado com sucesso!"
      );
    }
  } catch (err) {
    console.error("Erro ao gerar resumo:", err);
    alert("Erro ao gerar resumo. Verifique a chave da API e tente novamente.");
  }
};

const downloadTranscript = () => {
  const filename = `transcricao-${formatTimestamp()}.txt`;
  downloadFile(transcript.value, filename);
};

const saveWithoutSummary = () => {
  if (!transcript.value.trim()) {
    alert("N√£o h√° transcri√ß√£o para salvar.");
    return;
  }

  const meeting = saveMeeting(transcript.value, null);
  emit("summary-generated", meeting);

  // Notifica√ß√£o de sucesso
  if (window.electronAPI && window.electronAPI.showNotification) {
    window.electronAPI.showNotification(
      "Reuni√£o Salva",
      "A transcri√ß√£o foi salva com sucesso!"
    );
  }
};

const onBlackHoleConfigured = (deviceInfo) => {
  console.log('‚úÖ BlackHole configurado:', deviceInfo);

  // Notifica√ß√£o de sucesso
  if (window.electronAPI?.showNotification) {
    window.electronAPI.showNotification(
      "BlackHole Configurado",
      `${deviceInfo.label} pronto para captura completa!`
    );
  }
};


// Watchers
watch(isRecording, (newValue) => {
  if (!newValue) {
    if (durationInterval) {
      clearInterval(durationInterval);
      durationInterval = null;
    }
  }
});// Processamento autom√°tico da transcri√ß√£o ap√≥s parar grava√ß√£o
watch(hasAudio, (val) => {
  if (val && !transcript.value && !isProcessing.value) {
    // Auto-transcri√ß√£o ap√≥s parar grava√ß√£o
    processAudio();
  }
});

// Cleanup
onMounted(() => {
  return () => {
    if (durationInterval) {
      clearInterval(durationInterval);
    }
  };
});
</script>
