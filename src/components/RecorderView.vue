<template>
  <div class="h-full flex flex-col bg-white">
    <!-- Header -->
    <div class="border-b border-gray-200 px-6 py-4">
      <div class="flex items-center justify-between">
        <div>
          <h2 class="text-xl font-semibold text-gray-900">Nova Reuni√£o</h2>
          <p class="text-sm text-gray-500 mt-1">
            {{
              isRecording ? "Grava√ß√£o em andamento..." : "Pronto para gravar"
            }}
          </p>
        </div>

        <div class="flex items-center space-x-3">
          <StatusIndicator
            :is-active="isRecording"
            :status-text="
              isRecording ? formatDuration(recordingDuration) : 'Parado'
            "
          />
          <RecordingControls
            :is-recording="isRecording"
            :is-supported="isSupported"
            :is-processing="isProcessing"
            :transcript="transcript"
            @start-recording="startRecording"
            @stop-recording="stopRecording"
            @clear-transcript="clearTranscript"
          />
        </div>
      </div>
    </div>

    <!-- Conte√∫do principal -->
    <div class="flex-1 overflow-y-auto p-6">
      <!-- OpenAI Configuration -->
      <OpenAIConfig
        :has-open-a-i-configured="hasOpenAIConfigured()"
        :on-configure-open-a-i="setOpenAIApiKey"
        :on-test-connection="testOpenAIConnection"
        @configured="onOpenAIConfigured"
        @reset="onOpenAIReset"
      />


      <!-- Alerts -->
      <AlertBox
        v-if="error"
        type="error"
        title="Erro na grava√ß√£o"
        :message="error"
      />

      <AlertBox
        v-if="!isSupported"
        type="warning"
        title="Captura n√£o suportada"
        message="Nenhuma API de √°udio est√° dispon√≠vel. Verifique permiss√µes do sistema e reinicie o aplicativo."
      />

      <!-- Status da API - Simplificado -->
      <AlertBox
        v-if="apiStatus && apiStatus.status === 'error'"
        type="error"
        title="API indispon√≠vel"
        :message="apiStatus.message"
      />

      <AlertBox
        v-if="isProcessing"
        type="info"
        title="Processando..."
        :message="!transcript ? 'Transcrevendo √°udio' : 'Gerando resumo'"
      />

      <!-- √Årea de transcri√ß√£o -->
      <div class="space-y-6">
        <TranscriptDisplay
          :transcript="transcript"
          :is-recording="isRecording"
        />

        <PostRecordingActions
          v-if="transcript && !isRecording && !isProcessing"
          @generate-summary="generateSummary"
          @download-transcript="downloadTranscript"
          @save-transcript="saveWithoutSummary"
        />

      </div>
    </div>
  </div>
</template>

<script setup>
import { onMounted, onUnmounted, ref, watch } from "vue";
import { useConfig } from "../composables/useConfig.js";
import { useHistory } from "../composables/useHistory.js";
import { useRecorder } from "../composables/useRecorder.js";
import {
  downloadFile,
  formatDuration,
  formatTimestamp,
} from "../utils/formatters.js";

// UI Components
import PostRecordingActions from "./recorder/PostRecordingActions.vue";
import RecordingControls from "./recorder/RecordingControls.vue";
import TranscriptDisplay from "./recorder/TranscriptDisplay.vue";
import AlertBox from "./ui/AlertBox.vue";
import OpenAIConfig from "./ui/OpenAIConfig.vue";
import StatusIndicator from "./ui/StatusIndicator.vue";

// Emits
const emit = defineEmits(["summary-generated"]);

// Composables
const {
  isRecording,
  isProcessing,
  isSupported,
  transcript,
  error,
  startRecording: startRec,
  stopRecording: stopRec,
  clearTranscript,
  transcribeAudio,
  generateSummaryFromTranscript,
  hasAudio,
  audioBlob,
  setOpenAIApiKey,
  testOpenAIConnection,
  estimateTranscriptionCost,
  hasOpenAIConfigured,
} = useRecorder();

const { saveMeeting } = useHistory();
const { apiStatus } = useConfig();

// Estado local
const recordingDuration = ref(0);
let durationInterval = null;

// Listener para iniciar grava√ß√£o automaticamente (nova implementa√ß√£o)
let removeStartRecordingListener = null;

onMounted(() => {
  // Registra listener para detec√ß√£o autom√°tica de reuni√£o
  if (window.electronAPI?.onStartRecording) {
    removeStartRecordingListener = window.electronAPI.onStartRecording(
      (meetingData) => {
        console.log("üé¨ Reuni√£o detectada automaticamente:", meetingData);

        // Inicia grava√ß√£o automaticamente se n√£o estiver gravando
        if (!isRecording.value && !isProcessing.value) {
          console.log("üöÄ Iniciando grava√ß√£o autom√°tica...");
          startRecording();

          // Mostra notifica√ß√£o de feedback
          if (window.electronAPI?.showNotification) {
            window.electronAPI.showNotification(
              "Grava√ß√£o Iniciada",
              `Grava√ß√£o autom√°tica iniciada para ${meetingData.app}`
            );
          }
        } else {
          console.log("‚ö†Ô∏è Grava√ß√£o j√° em andamento, ignorando...");
        }
      }
    );
  }
});

// Limpa listener quando o componente √© desmontado
onUnmounted(() => {
  if (removeStartRecordingListener) {
    removeStartRecordingListener();
  }
  if (durationInterval) {
    clearInterval(durationInterval);
  }
});

// Usando fun√ß√£o utilitaria importada

// M√©todos
const startRecording = async () => {
  await startRec();
  if (isRecording.value) {
    recordingDuration.value = 0;
    durationInterval = setInterval(() => {
      recordingDuration.value++;
    }, 1000);
  }
};

const stopRecording = () => {
  stopRec();
  if (durationInterval) {
    clearInterval(durationInterval);
    durationInterval = null;
  }
};

const processAudio = async () => {
  if (!audioBlob.value) {
    alert("Nenhum √°udio capturado.");
    return;
  }
  try {
    const fileSizeMB = audioBlob.value.size / (1024 * 1024);
    const durationMinutes = (recordingDuration.value || 0) / 60;

    // Mostrar info do arquivo para o usu√°rio
    console.log(
      `üéµ Processando √°udio: ${fileSizeMB.toFixed(
        1
      )}MB, ${durationMinutes.toFixed(1)} minutos`
    );

    await transcribeAudio();

    if (window.electronAPI?.showNotification) {
      window.electronAPI.showNotification(
        "Transcri√ß√£o Conclu√≠da",
        `√Åudio de ${durationMinutes.toFixed(1)} min processado com sucesso!`
      );
    }
  } catch (err) {
    console.error("Erro ao transcrever √°udio:", err);

    // Mensagens de erro mais espec√≠ficas
    let errorMessage = "Erro ao transcrever √°udio. ";

    if (err.message.includes("limit") || err.message.includes("grande")) {
      errorMessage += "Processando reuni√£o longa em partes menores. Aguarde...";
    } else if (
      err.message.includes("timeout") ||
      err.message.includes("Timeout")
    ) {
      errorMessage += "A API demorou muito para processar. Tente novamente.";
    } else if (err.message.includes("API ausente")) {
      errorMessage += "Chave da API n√£o configurada. Verifique o arquivo .env";
    } else if (err.message.includes("upload")) {
      errorMessage += "Falha no upload do arquivo. Verifique sua conex√£o.";
    } else {
      errorMessage += err.message;
    }

    alert(errorMessage);
  }
};

const generateSummary = async () => {
  if (!transcript.value) {
    alert("Nenhuma transcri√ß√£o dispon√≠vel.");
    return;
  }
  try {
    const summary = await generateSummaryFromTranscript();
    const meeting = saveMeeting(transcript.value, summary);
    emit("summary-generated", meeting);
    if (window.electronAPI?.showNotification) {
      window.electronAPI.showNotification(
        "Resumo Gerado",
        "Resumo criado com sucesso!"
      );
    }
  } catch (err) {
    console.error("Erro ao gerar resumo:", err);
    alert("Erro ao gerar resumo. Verifique a chave da API e tente novamente.");
  }
};

const downloadTranscript = () => {
  const filename = `transcricao-${formatTimestamp()}.txt`;
  downloadFile(transcript.value, filename);
};

const saveWithoutSummary = () => {
  if (!transcript.value.trim()) {
    alert("N√£o h√° transcri√ß√£o para salvar.");
    return;
  }

  const meeting = saveMeeting(transcript.value, null);
  emit("summary-generated", meeting);

  // Notifica√ß√£o de sucesso
  if (window.electronAPI && window.electronAPI.showNotification) {
    window.electronAPI.showNotification(
      "Reuni√£o Salva",
      "A transcri√ß√£o foi salva com sucesso!"
    );
  }
};

// OpenAI configuration handlers
const onOpenAIConfigured = () => {
  console.log('‚úÖ OpenAI configurado com sucesso');
};

const onOpenAIReset = () => {
  console.log('üîÑ OpenAI resetado');
};

// Watchers
watch(isRecording, (newValue) => {
  if (!newValue) {
    if (durationInterval) {
      clearInterval(durationInterval);
      durationInterval = null;
    }
  }
});// Processamento autom√°tico da transcri√ß√£o ap√≥s parar grava√ß√£o
watch(hasAudio, (val) => {
  if (val && !transcript.value && !isProcessing.value) {
    // Auto-transcri√ß√£o ap√≥s parar grava√ß√£o
    processAudio();
  }
});

// Cleanup
onMounted(() => {
  return () => {
    if (durationInterval) {
      clearInterval(durationInterval);
    }
  };
});
</script>
