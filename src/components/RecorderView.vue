<template>
  <div class="h-full flex flex-col bg-white">
    <!-- Header -->
    <div class="border-b border-gray-200 px-6 py-4">
      <div class="flex items-center justify-between">
        <div>
          <h2 class="text-xl font-semibold text-gray-900">Nova Reuni√£o</h2>
          <p class="text-sm text-gray-500 mt-1">
            {{
              isRecording ? "Grava√ß√£o em andamento..." : "Pronto para gravar"
            }}
          </p>
        </div>

        <div class="flex items-center space-x-3">
          <StatusIndicator
            :is-active="isRecording"
            :status-text="
              isRecording ? formatDuration(recordingDuration) : 'Parado'
            "
          />
          <AudioCaptureIndicator
            v-if="isRecording || audioCaptureType !== 'unknown'"
            :capture-type="audioCaptureType"
            :is-capturing-full-meeting="isCapturingFullMeeting"
            :source-count="audioSources.length"
            :is-capturing-input="isCapturingInput"
            :is-capturing-output="isCapturingOutput"
            :audio-quality="audioQuality"
          />
          <RecordingControls
            :is-recording="isRecording"
            :is-supported="isSupported"
            :is-processing="isProcessing"
            :transcript="transcript"
            @start-recording="startRecording"
            @stop-recording="stopRecording"
            @clear-transcript="clearTranscript"
          />
        </div>
      </div>
    </div>

    <!-- Conte√∫do principal -->
    <div class="flex-1 overflow-y-auto p-6">

      <!-- Indicador de Transcri√ß√£o em Tempo Real -->
      <RealTimeTranscriptionIndicator
        v-if="isRecording || (realTimeTranscription && realTimeTranscription.sessionId)"
        :real-time-transcription="realTimeTranscription"
        :cache="cache"
        @toggle-real-time="toggleRealTimeTranscription"
        @clear-cache="clearTranscriptionCache"
      />

      <!-- Bot√£o de teste de captura de √°udio -->
      <AudioTestButton v-if="!isRecording" />

      <!-- Guia de configura√ß√£o do Stereo Mix -->
      <StereoMixGuide
        v-if="showStereoMixGuide && !isRecording"
        @close="showStereoMixGuide = false"
      />


      <!-- Alerts -->
      <AlertBox
        v-if="error"
        type="error"
        title="Erro na grava√ß√£o"
        :message="error"
      />

      <AlertBox
        v-if="!isSupported"
        type="warning"
        title="Captura n√£o suportada"
        message="Nenhuma API de √°udio est√° dispon√≠vel. Verifique permiss√µes do sistema e reinicie o aplicativo."
      />

      <!-- Alerta quando captura completa est√° ativa -->
      <AlertBox
        v-if="isRecording && audioCaptureType === 'system'"
        type="success"
        title="‚úÖ Captura completa ativa"
        message="Gravando TODO o √°udio do sistema - sua voz + √°udio dos outros participantes."
      />

      <!-- Alerta quando captura Notion est√° ativa -->
      <AlertBox
        v-if="isRecording && audioCaptureType === 'notion'"
        type="success"
        title="üéØ Captura igual ao Notion ativa"
        message="Gravando microfone + sistema mixados em uma √∫nica transcri√ß√£o - sua voz + todos os participantes."
      />

      <!-- Alerta quando apenas microfone -->
      <AlertBox
        v-if="isRecording && audioCaptureType === 'microphone'"
        type="warning"
        title="‚ö†Ô∏è Apenas microfone detectado"
        message="Capturando apenas sua voz. Desktop Capturer n√£o conseguiu acessar o √°udio do sistema."
      />

      <!-- Status da API - Simplificado -->
      <AlertBox
        v-if="apiStatus && apiStatus.status === 'error'"
        type="error"
        title="API indispon√≠vel"
        :message="apiStatus.message"
      />

      <AlertBox
        v-if="isProcessing"
        type="info"
        title="Processando..."
        :message="!transcript ? 'Transcrevendo √°udio' : 'Gerando resumo'"
      />

      <!-- √Årea de transcri√ß√£o -->
      <div class="space-y-6">
        <TranscriptDisplay
          :transcript="transcript"
          :is-recording="isRecording"
        />

        <PostRecordingActions
          v-if="transcript && !isRecording && !isProcessing"
          @generate-summary="generateSummary"
          @download-transcript="downloadTranscript"
          @save-transcript="saveWithoutSummary"
        />

      </div>
    </div>
  </div>
</template>

<script setup>
import { onMounted, onUnmounted, ref, watch } from "vue";
import { useConfig } from "../composables/useConfig.js";
import { useHistory } from "../composables/useHistory.js";
import { useRecorder } from "../composables/useRecorder.js";
import {
  downloadFile,
  formatDuration,
  formatTimestamp,
} from "../utils/formatters.js";

// UI Components
import PostRecordingActions from "./recorder/PostRecordingActions.vue";
import RealTimeTranscriptionIndicator from "./recorder/RealTimeTranscriptionIndicator.vue";
import RecordingControls from "./recorder/RecordingControls.vue";
import TranscriptDisplay from "./recorder/TranscriptDisplay.vue";
import AlertBox from "./ui/AlertBox.vue";
import AudioCaptureIndicator from "./ui/AudioCaptureIndicator.vue";
import AudioTestButton from "./ui/AudioTestButton.vue";
import StatusIndicator from "./ui/StatusIndicator.vue";
import StereoMixGuide from "./ui/StereoMixGuide.vue";

// Emits
const emit = defineEmits(["summary-generated"]);

// Composables
const {
  isRecording,
  isProcessing,
  isSupported,
  transcript,
  error,
  startRecording: startRec,
  stopRecording: stopRec,
  clearTranscript,
  transcribeAudio,
  generateSummaryFromTranscript,
  hasAudio,
  audioBlob,
  setOpenAIApiKey,
  testOpenAIConnection,
  estimateTranscriptionCost,
  hasOpenAIConfigured,
  // Novos: estado da captura de √°udio
  audioCaptureType,
  isCapturingFullMeeting,
  audioSources,
  isCapturingInput,
  isCapturingOutput,
  audioQuality,
  detectedMeetingApp,
  // Transcri√ß√£o em tempo real
  realTimeTranscription,
  cache,
} = useRecorder();

const { saveMeeting } = useHistory();
const { apiStatus } = useConfig();

// Estado local
const recordingDuration = ref(0);
const showStereoMixGuide = ref(false);
let durationInterval = null;

// Listener para iniciar grava√ß√£o automaticamente (nova implementa√ß√£o)
let removeStartRecordingListener = null;

onMounted(() => {
  // Registra listener para detec√ß√£o autom√°tica de reuni√£o
  if (window.electronAPI?.onStartRecording) {
    removeStartRecordingListener = window.electronAPI.onStartRecording(
      (meetingData) => {
        console.log("üé¨ Reuni√£o detectada automaticamente:", meetingData);

        // Inicia grava√ß√£o automaticamente se n√£o estiver gravando
        if (!isRecording.value && !isProcessing.value) {
          console.log("üöÄ Iniciando grava√ß√£o autom√°tica...");
          startRecording();

          // Mostra notifica√ß√£o de feedback
          if (window.electronAPI?.showNotification) {
            window.electronAPI.showNotification(
              "Grava√ß√£o Iniciada",
              `Grava√ß√£o autom√°tica iniciada para ${meetingData.app}`
            );
          }
        } else {
          console.log("‚ö†Ô∏è Grava√ß√£o j√° em andamento, ignorando...");
        }
      }
    );
  }
});

// Limpa listener quando o componente √© desmontado
onUnmounted(() => {
  if (removeStartRecordingListener) {
    removeStartRecordingListener();
  }
  if (durationInterval) {
    clearInterval(durationInterval);
  }
});

// Usando fun√ß√£o utilitaria importada

// M√©todos
const startRecording = async () => {
  try {
    console.log('üî¥ [RecorderView] Iniciando grava√ß√£o...');

    // Reset do estado antes de iniciar
    error.value = null;
    recordingDuration.value = 0;

    // Chama a fun√ß√£o do composable
    await startRec();

    if (isRecording.value) {
      console.log('‚úÖ [RecorderView] Grava√ß√£o iniciada, configurando timer...');
      recordingDuration.value = 0;
      durationInterval = setInterval(() => {
        recordingDuration.value++;
      }, 1000);
    } else {
      console.warn('‚ö†Ô∏è [RecorderView] Grava√ß√£o n√£o iniciou (isRecording ainda false)');
    }
  } catch (startError) {
    console.error('‚ùå [RecorderView] Erro ao iniciar grava√ß√£o:', startError);
    error.value = `Erro ao iniciar: ${startError.message}`;
  }
};

const stopRecording = () => {
  stopRec();
  if (durationInterval) {
    clearInterval(durationInterval);
    durationInterval = null;
  }
};

const processAudio = async () => {
  if (!audioBlob.value) {
    alert("Nenhum √°udio capturado.");
    return;
  }
  try {
    const fileSizeMB = audioBlob.value.size / (1024 * 1024);
    const durationMinutes = (recordingDuration.value || 0) / 60;

    // Mostrar info do arquivo para o usu√°rio
    console.log(
      `üéµ Processando √°udio: ${fileSizeMB.toFixed(
        1
      )}MB, ${durationMinutes.toFixed(1)} minutos`
    );

    await transcribeAudio();

    if (window.electronAPI?.showNotification) {
      window.electronAPI.showNotification(
        "Transcri√ß√£o Conclu√≠da",
        `√Åudio de ${durationMinutes.toFixed(1)} min processado com sucesso!`
      );
    }
  } catch (err) {
    console.error("Erro ao transcrever √°udio:", err);

    // Mensagens de erro mais espec√≠ficas
    let errorMessage = "Erro ao transcrever √°udio. ";

    if (err.message.includes("limit") || err.message.includes("grande")) {
      errorMessage += "Processando reuni√£o longa em partes menores. Aguarde...";
    } else if (
      err.message.includes("timeout") ||
      err.message.includes("Timeout")
    ) {
      errorMessage += "A API demorou muito para processar. Tente novamente.";
    } else if (err.message.includes("API ausente")) {
      errorMessage += "Chave da API n√£o configurada. Verifique o arquivo .env";
    } else if (err.message.includes("upload")) {
      errorMessage += "Falha no upload do arquivo. Verifique sua conex√£o.";
    } else {
      errorMessage += err.message;
    }

    alert(errorMessage);
  }
};

const generateSummary = async () => {
  if (!transcript.value) {
    alert("Nenhuma transcri√ß√£o dispon√≠vel.");
    return;
  }
  try {
    const summary = await generateSummaryFromTranscript();
    const meeting = saveMeeting(transcript.value, summary);
    emit("summary-generated", meeting);
    if (window.electronAPI?.showNotification) {
      window.electronAPI.showNotification(
        "Resumo Gerado",
        "Resumo criado com sucesso!"
      );
    }
  } catch (err) {
    console.error("Erro ao gerar resumo:", err);
    alert("Erro ao gerar resumo. Verifique a chave da API e tente novamente.");
  }
};

const downloadTranscript = () => {
  const filename = `transcricao-${formatTimestamp()}.txt`;
  downloadFile(transcript.value, filename);
};

const saveWithoutSummary = () => {
  if (!transcript.value.trim()) {
    alert("N√£o h√° transcri√ß√£o para salvar.");
    return;
  }

  const meeting = saveMeeting(transcript.value, null);
  emit("summary-generated", meeting);

  // Notifica√ß√£o de sucesso
  if (window.electronAPI && window.electronAPI.showNotification) {
    window.electronAPI.showNotification(
      "Reuni√£o Salva",
      "A transcri√ß√£o foi salva com sucesso!"
    );
  }
};

// Fun√ß√µes de controle da transcri√ß√£o em tempo real
const toggleRealTimeTranscription = () => {
  realTimeTranscription.value.enabled = !realTimeTranscription.value.enabled;
  console.log('üîÑ Transcri√ß√£o em tempo real:', realTimeTranscription.value.enabled ? 'Ativada' : 'Desativada');
};

const clearTranscriptionCache = () => {
  cache.clearAllCache();
  console.log('üóëÔ∏è Cache de transcri√ß√µes limpo');
};

// Watchers
watch(isRecording, (newValue) => {
  if (!newValue) {
    if (durationInterval) {
      clearInterval(durationInterval);
      durationInterval = null;
    }
  }
});// Processamento autom√°tico da transcri√ß√£o ap√≥s parar grava√ß√£o
watch(hasAudio, (val) => {
  if (val && !transcript.value && !isProcessing.value) {
    // Auto-transcri√ß√£o ap√≥s parar grava√ß√£o
    processAudio();
  }
});

// Cleanup
onMounted(() => {
  return () => {
    if (durationInterval) {
      clearInterval(durationInterval);
    }
  };
});
</script>
